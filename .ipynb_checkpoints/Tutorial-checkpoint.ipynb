{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dependencies** \n",
    "###### (all of these packages should be added to the python path in the .bashrc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 2 (several of the packages below are not compatible yet with python 3)\n",
    "\n",
    "HEALPix (and dependencies) (from https://healpix.jpl.nasa.gov/)\n",
    "\n",
    "Healpy (from pip installer) - for HEALPix manipulations\n",
    "\n",
    "randomgen (from pip installer) - for random number generation\n",
    "\n",
    "pynverse (from pip installer) - for fast function inversion\n",
    "\n",
    "cmocean (from pip installer) - for colorbars\n",
    "\n",
    "skymapper (from https://github.com/pmelchior/skymapper) - for map visualization\n",
    "\n",
    "PyFITS<=3.3 (from pip installer) (*NB: Flipper is **not** compatible with PyFITS 3.5 currently*) - for FITS functions\n",
    "\n",
    "tqdm (from pip installer) - for timing multiprocessing\n",
    "\n",
    "Flipper (from https://github.com/sudeepdas/flipper) {this needs PyFits and astropy installed via pip} - for T-mode manupulations\n",
    "\n",
    "FlipperPol (from https://github.com/msyriac/flipperPol) - for polarization map manipulations\n",
    "\n",
    "PolSpice (from http://www2.iap.fr/users/hivon/software/PolSpice/) - for C_l computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NB: There may be errors relating to the CardList() function when running Flipper depending on the version of PyFITS installed. If this persists, change the PyFITS version to 3.3 or replace CardList() with Header() in the Flipper LiteMap.py file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a full description of the code please refer to Philcox, Sherwin & van Engelen (MNRAS, 2018) or contact ohep2@alumni.cam.ac.uk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Split Map into Tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code base for this process was written by Alex van Engelen (CITA) and partitions a full-sky HEALPix TQU polarization map into tiles of a desired width. \n",
    "\n",
    "## 1.1) Dust Map\n",
    "\n",
    "This is controlled via the python `tile_creation/cutoutmapsPhilcox.py` file. To select tile-sizes and load HEALPix maps a `.dict` dictionary should be created. A sample is given in `tile_creation/sample_dictionary.dict`.\n",
    "\n",
    "The dictionary file contains several important parameters including the location of the HEALPix file and tile_widths and must be altered for each new test. The parameters are explained in the sample dictionary comments.\n",
    "\n",
    "We note that the HEALPix map should be of high resolution (NSIDE=2048) and should be a dust-map (e.g. Vansyngel+ 2017 high-resolution map, Planck FFP10 etc.). Instrumental noise and lensing are simulated within the HADES code and added to cut-outs of this map later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** to analyse a section of the sky (which is far less resource intensive) a HEALPix Mask file must be provided, upgraded to the same resolution as the HEALPix dust map. The mask used in the nominal HADES paper can be provided on request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now cut out the tiles using this script and the dictionary as follows. This may take a while depending on the processor speed and can generate several 10s GBs of files depending on the settings used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -u ~/HADES/tile_creation/cutoutmapsPhilcox.py ~/HADES/tile_creation/sample_dictionary.dict```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make power maps from these tiles (this configures the mask files and also must be done for each new HEALPix map or tile configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -u ~/HADES/tile_creation/powerMapsPhilcox.py ~/HADES/tile_creation/sample_dictionary.dict```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This completes the pre-configuration of map 'tiles'. The HEALPix map (with an appropriate mask) has now been partitioned into a number of small tiles of desired width. These are located in the directory specified in the edited dictionary file in the subdirectory `3deg1/` {if tiles of width 3deg separated by 1deg were chosen}. These files are later found and analysed by the `hades` code.\n",
    "\n",
    "***A note on file structure***:\n",
    "*The tile naming system has the following structure: *\n",
    "\n",
    "*fvsmap{TYPE}_{NUMBER}.fits \n",
    "\n",
    "where TYPE specifies the Mask, T, Q or U polarizations and the NUMBER specifies the positions (with RA and Dec coordinates of the map centers given in the pickle files fvsmapDecs.pkl and fvsmapRAs.pkl).*\n",
    "\n",
    "*NB: The prefix 'fvs' is irrelevant here but used throughout the code so should not be changed. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Lensing Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above techniques should now be rerun for a full-sky HEALPix lensing map to give the lensing contributions to the overall simulation. This is created as in section 1.1, except that the `sample_dictionary.dict` file should link to the lensing map and files should be saved in a subdirectory of the work directory titled `lens/`. A sample dictionary for this is given as `sample_lensing.dict`.\n",
    "\n",
    "*The lensing map used by the authors can be obtained upon request.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Tile Analysis with HADES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Parameter Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essential (and non-essential) parameters for the analysis of a HEALPix map are controlled by a class in the `hades/params.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the parameters\n",
    "from hades.params import BICEP\n",
    "import numpy as np\n",
    "a=BICEP() # parameter class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are described in detail in the python file. The key parameters to alter are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.hades_dir = '/home/oliver/HADES/' # directory where HADES is installed\n",
    "a.root_dir = '/home/oliver/hades_testing/' # directory to house all simulation cut-outs + analysis products. This must be the directory housing the (e.g. 3deg3/) cut-outs.\n",
    "a.full_lens_dir='/home/oliver/hades_testing/lens/' # directory housing lensing cut-outs\n",
    "a.flipU = True # This converts between COSMO [in many input maps] and IAU [used by flipper] polarisation conventions. If true, this reverses the sign of the U-polarisation map which has non-trivial effects on the analysis.\n",
    "    \n",
    "## Tile parameters\n",
    "a.map_size = 3 # tile (cut-out section) width in degrees\n",
    "a.sep = 3 # separation of the center of each tile. This may be set as less than the map_size to allow higher resolution plots with overlapping tiles but destroys the statistical independence\n",
    "\n",
    "## MC parameters\n",
    "a.N_sims = 500 # No. of MC simulations used to create parameter distributions\n",
    "a.N_bias = 500 # No. simulations used for realisation-dependent debiasing\n",
    "\n",
    "## Experimental parameters\n",
    "a.freq = 150 # Desired map frequency in GHz. Currently only 150 GHz (peak BICEP sensitivity) and 353 GHz (original simulations) are implemented - [these rely on non-linear color conversions\n",
    "a.f_dust = 1. # Scalable dust fraction where f_dust = 1 has no cleaning and f_dust = 0 has 100% dust cleaning efficiency.\n",
    "\n",
    "## Noise model [see table 1 of Philcox+2018 for full descriptions]\n",
    "experiment_profiles= ['Zero', 'BICEP2', 'Simons', 'S4'] # Loaded experimental profiles\n",
    "experiment_profile_index = 0\n",
    "# This loads the relevant FWHM, noise_power and delensing_fractions\n",
    "\n",
    "# These can be overwritten e.g.\n",
    "a.FWHM = 30. # Experimental noise FWHM [theta_FWHM] in arcmin\n",
    "a.noise_power = 5. # Experimental noise_power [delta_P] in uK-arcmin\n",
    "a.delensing_fraction = 1. # Delensing efficiency, where 0.1 implies C_l_lens is reduced by 90%.\n",
    "\n",
    "## Null testing parameters [paper figure 2]\n",
    "a.f_dust_all = list(np.arange(1.0,-0.05,-0.05)) # List of values of dust fraction to be tested.\n",
    "a.err_repeats = 10 # Number of times to repeat each data-point (for error-bars)\n",
    "\n",
    "## Noise parameter space studies [paper figure 4]\n",
    "a.noi_par_NoisePower=np.linspace(0.1,5.1,20) # noise_power ranges\n",
    "a.noi_par_FWHM=np.linspace(0,31.,20) # noise FWHM values\n",
    "a.noi_par_delensing=[0.1,1.0] # delensing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Analysis of a Single Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here describe how to run the dust analysis for a given HEALPix map, adding the relevant levels of noise, FWHM and lensing as described above. First the `hades/params.py` file must be configured as described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a single analysis on each tile of a HEALPix map (created in section 1 above), we use the `padded_debiased_wrap.py` file. This adds noise modes to each tile separately (as was the default setting in the HADES paper). Lensing modes are added from a Planck FFP10 lensing map.\n",
    "\n",
    "(NB: We also provide HTCondor submission scripts (`batch_maps.sub`) which are designed to run the `padded_debiased_wrap.py` for all cut-out tiles on a computing system utilising HTCondor, running the code via the `batch_maps.sh` bash wrapper. These files are currently configured for a specific cluster Condor installation and would need cluster-dependent modification before use.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the analysis for a single tile run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -u ~/HADES/hades/full_lens_wrap.py XX```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where XX is the number of the tile to analyse. NB: The script will close automatically if the tile number is greater than the total number of tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analyzes the tile and the data is saved as a `.npy` file in the directory `LensedPaddedBatchData/f{X1}_ms{X2}_s{X3}_fw{X4}_np{X5}_d{X6}/` where X1 = frequency (GHz), X2 = tile size (degrees), X3 = tile center separation (degrees), X4 = noise FWHM (arcmin), X5 = noise power (microK-arcmin), X6 = delensing fraction.\n",
    "\n",
    "It is necessary to run this python file on all tiles. This can be done via python multiprocessing (which will take around an hour for a standard implementation on a desktop or much faster on a cluster) or via an HTCondor system. An implementation of python multiprocessing to run this can be found in the `hades/multi_wrap.py` e.g.\n",
    "\n",
    "```python -u ~/HADES/hades/multi_wrap.py```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the hexadecapole quantities are computed for all tiles in the desired region we must reconstruct the output parameters. This is done via the following script, which reads in the hexadecapole parameter estimates previously computed, using the modelling parameters in the `.params` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The significance of a detection of dust anisotropy in this region is 45.86 sigma\n"
     ]
    }
   ],
   "source": [
    "from hades.hex_wrap import patch_hexadecapole\n",
    "\n",
    "patch_hexadecapole(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot keyword in `patch_hexadecapole()` creates a .png plot in the subdirectory `PatchHexCorrectedPow` of the working directory e.g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hades/demonstration_histogram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue histogram gives the (bias-corrected) values of the patch-averaged hexadecapole parameter $\\mathcal{H}^2$ from MC simulations (which should have $\\langle{\\mathcal{H}^2\\rangle}=0$). The red line indicates the debiased hexadecapole statistic obtained from the 'data' (the input HEALPix dust map) which is in clear tension with the histogram. The detection significance is obtained by fitting the MC $\\mathcal{H}^2$ distribution to a Gaussian (appropriate for large $N_\\mathrm{sims}$). (NB: This plot only used $N_\\mathrm{sims}=100$ for speed, which is sub-optimal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the hexadecapole parameters in full we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC Debiased H2: -5.04e-43 +/- 1.76e-26\n",
      "Data Debiased H2: 2.38e-25\n",
      "H2 realization dependent bias term: 1.97e-26\n",
      "H2 detection significance: 45.9 sigma\n"
     ]
    }
   ],
   "source": [
    "mean_H2_MC,err_H2_MC,data_H2_estimate,H2_significance,_,bias\\\n",
    "    =patch_hexadecapole(returnAll=True)\n",
    "\n",
    "print('MC Debiased H2: %.2e +/- %.2e' %(mean_H2_MC,err_H2_MC))\n",
    "print('Data Debiased H2: %.2e' %(data_H2_estimate))\n",
    "print('H2 realization dependent bias term: %.2e' %bias)\n",
    "print('H2 detection significance: %.1f sigma' %H2_significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Basic Structure of the HADES wrapper \n",
    "*This charts the basic processes included in the `lensed_wrap()` function run by the`full_lens_wrap.py` wrapper. All functions mentioned are found in the `hades/` package.*\n",
    "\n",
    "1) Create Fourier-space and power-space maps of T,Q,U and the mask via the `.PaddedPower.MakePowerAndFourierMaps` function.\n",
    "\n",
    "2) Degrade these to the correct resolution for efficiency using the `.PaddedPower.DegradeMap/DegradeFourier` functions.\n",
    "\n",
    "3) Multiply the power maps by the desired dust fraction (and window-correction factor).\n",
    "\n",
    "4) Compute the Fourier-space lensing map via the `.lens_power.MakeFourierLens` function.\n",
    "\n",
    "5) Compute a fourier-map of the same size using only noise contributions via the `.NoisePower.noise_model` and `.PaddedPower.fourier_noise_test` functions.\n",
    "\n",
    "6) Combine lensing, dust and noise maps together linearly. \n",
    "\n",
    "7) Compute the anisotropy parameters via the `KKdebiased.derotated_estimator` function.\n",
    "\n",
    "8) Find the realization-dependent bias factor of the combined map, first binning in annuli via `.PowerMap.oneD_binning` then creating bias simulations via `.RandomField.padded_fill_from_Cell`. These are analyzed via the `KKdebiased.derotated_estimator` as before.\n",
    "\n",
    "9) Compute MC simulations via `padded_fill_from_Cell` and `derotated_estimator` as before.\n",
    "\n",
    "10) Compute the hexadecapole power and other anisotropy parameters and their distributions and return these.\n",
    "\n",
    "11) These are saved to a `.npy` file by the main wrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Plotting the Map Distributions\n",
    "\n",
    "We now consider how to plot the hexadecapole parameters for visualization. This visualization can be improved by using overlapping tiles (although this should not be used for the hexadecapole parameter significance since the tiles are no longer independence). \n",
    "\n",
    "Here we use a simple configuration with 3 degree width cells, separated by 3 degrees (non-overlapping) created as described above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 1 of 245\n",
      "loading 101 of 245\n",
      "loading 201 of 245\n",
      "Generating patch map 1 of 19\n",
      "Generating patch map 2 of 19\n",
      "Generating patch map 3 of 19\n",
      "Generating patch map 4 of 19\n",
      "Generating patch map 5 of 19\n",
      "Generating patch map 6 of 19\n",
      "Generating patch map 7 of 19\n",
      "Generating patch map 8 of 19\n",
      "Generating patch map 9 of 19\n",
      "Generating patch map 10 of 19\n",
      "Generating patch map 11 of 19\n",
      "Generating patch map 12 of 19\n",
      "Generating patch map 13 of 19\n",
      "Generating patch map 14 of 19\n",
      "Generating patch map 15 of 19\n",
      "Generating patch map 16 of 19\n",
      "Generating patch map 17 of 19\n",
      "Generating patch map 18 of 19\n",
      "Generating patch map 19 of 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hades.plotTools import hexadecapole_plots\n",
    "hexadecapole_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates 19 individual map in the `PaddedMaps/` subdirectory of the working directory e.g. for the angle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hades/angle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all plots the top axis shows Galactic RA whilst the left axis shows declination. (NB: The HADES paper used 0.5degree separation tiles to get increased resolution). \n",
    "\n",
    "The images created by this function are the following:\n",
    "- A: Amplitude [uK] and A_err: Amplitude Gaussian error [uK]\n",
    "- Afs/Afc: Hexadecapole parameters Af_s and Af_c [uK]\n",
    "- Af_err: Mean error in Af_s and Af_c parameters [uK]\n",
    "- angle and ang_err: Hexadecapole angle [degrees] and associated Gaussian-propagated error\n",
    "- epsilon and epsilon_err: Fractional hexadecapole anisotropy: H/A [dimensionless]\n",
    "- f_err: Mean error in f_s and f_c [dimensionless]\n",
    "- fs / fc: f_s and f_c fractional hexadecapole parameters [dimensionless]\n",
    "- Hex2Pow and Hex2PowErr: (non-debiased) H^2 estimate [uK^2]\n",
    "- Hex2PowSig: Significance of detection of debiased H^2 [sigma]\n",
    "- logHex2Pow: Logarithmic H^2 value [log(uK^2)]\n",
    "- prob_analyt: Analytic percentile of a tile-based measurement of $\\mathcal{H}^2$ compared to the MC simulation tile\n",
    "- prob_stat: Statistical percentile of this measurement\n",
    "\n",
    "The most important plots are of $\\mathcal{H}^2$, the amplitude $A$ and the hexadecapole angle $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: This is NOT correct function!! Need semilog scalings etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**IMMPORTANT NOTE TO SELF: Now using the files downloaded from my Cam server - not github. These are in the HADES/ folder but may not reflect later modifications this week. Old files are in the HADES_backup2/ folder. Must re-run hades tasks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
